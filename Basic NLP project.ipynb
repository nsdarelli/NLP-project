{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVvU82YdXT-e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "messages = pd.read_csv(\"SMSSpamCollection.txt\", sep='\\t', names=['lable', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1R6WPxAXUkY",
    "outputId": "e2322c4b-7fbe-42e4-d2f9-b27e1cac3b15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZFJ-rIOzYs5f",
    "outputId": "090f7ed8-941e-484d-9c1b-db6f9b3be76d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Please don't text me anymore. I have nothing else to say.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['message'].loc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1j_uQDbZTW1",
    "outputId": "1b161a32-c666-47b2-b96d-279a6ec3c4b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "112jRS-JZo5D"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "Lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttsLd6-oaK9D"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "\n",
    "for i in range(len(messages)):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  review = [Lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUilf6QGiVW1"
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "words=[]\n",
    "for sent in corpus:\n",
    "  sent_token = sent_tokenize(sent)\n",
    "  for word in sent_token:\n",
    "    words.append(simple_preprocess(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xEKAtvajfDF"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(words,window=5,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aq56TvLrj3Sa",
    "outputId": "7d1891d2-6094-4782-9500-714a74869f4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'get',\n",
       " 'ur',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'go',\n",
       " 'ok',\n",
       " 'day',\n",
       " 'free',\n",
       " 'know',\n",
       " 'come',\n",
       " 'like',\n",
       " 'time',\n",
       " 'good',\n",
       " 'got',\n",
       " 'love',\n",
       " 'text',\n",
       " 'want',\n",
       " 'send',\n",
       " 'need',\n",
       " 'one',\n",
       " 'txt',\n",
       " 'today',\n",
       " 'going',\n",
       " 'stop',\n",
       " 'home',\n",
       " 'lor',\n",
       " 'sorry',\n",
       " 'see',\n",
       " 'still',\n",
       " 'mobile',\n",
       " 'take',\n",
       " 'back',\n",
       " 'da',\n",
       " 'reply',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'tell',\n",
       " 'week',\n",
       " 'hi',\n",
       " 'phone',\n",
       " 'new',\n",
       " 'later',\n",
       " 'please',\n",
       " 'pls',\n",
       " 'co',\n",
       " 'msg',\n",
       " 'min',\n",
       " 'make',\n",
       " 'night',\n",
       " 'dear',\n",
       " 'message',\n",
       " 'well',\n",
       " 'say',\n",
       " 'thing',\n",
       " 'much',\n",
       " 'oh',\n",
       " 'hope',\n",
       " 'claim',\n",
       " 'great',\n",
       " 'hey',\n",
       " 'give',\n",
       " 'number',\n",
       " 'happy',\n",
       " 'wat',\n",
       " 'friend',\n",
       " 'work',\n",
       " 'way',\n",
       " 'yes',\n",
       " 'www',\n",
       " 'prize',\n",
       " 'let',\n",
       " 'right',\n",
       " 'tomorrow',\n",
       " 'already',\n",
       " 'tone',\n",
       " 'ask',\n",
       " 'win',\n",
       " 'said',\n",
       " 'life',\n",
       " 'cash',\n",
       " 'amp',\n",
       " 'yeah',\n",
       " 'im',\n",
       " 'really',\n",
       " 'meet',\n",
       " 'babe',\n",
       " 'find',\n",
       " 'miss',\n",
       " 'morning',\n",
       " 'thanks',\n",
       " 'last',\n",
       " 'uk',\n",
       " 'service',\n",
       " 'year',\n",
       " 'anything',\n",
       " 'care',\n",
       " 'would',\n",
       " 'com',\n",
       " 'also',\n",
       " 'lol',\n",
       " 'nokia',\n",
       " 'feel',\n",
       " 'every',\n",
       " 'keep',\n",
       " 'sure',\n",
       " 'pick',\n",
       " 'urgent',\n",
       " 'sent',\n",
       " 'contact',\n",
       " 'something',\n",
       " 'buy',\n",
       " 'gud',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'box',\n",
       " 'place',\n",
       " 'first',\n",
       " 'even',\n",
       " 'someone',\n",
       " 'help',\n",
       " 'guy',\n",
       " 'nice',\n",
       " 'went',\n",
       " 'tonight',\n",
       " 'next',\n",
       " 'wish',\n",
       " 'around',\n",
       " 'soon',\n",
       " 'show',\n",
       " 'word',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'money',\n",
       " 'sleep',\n",
       " 'late',\n",
       " 'many',\n",
       " 'per',\n",
       " 'chat',\n",
       " 'always',\n",
       " 'gonna',\n",
       " 'ya',\n",
       " 'sm',\n",
       " 'leave',\n",
       " 'wan',\n",
       " 'name',\n",
       " 'lot',\n",
       " 'dun',\n",
       " 'end',\n",
       " 'pm',\n",
       " 'st',\n",
       " 'told',\n",
       " 'special',\n",
       " 'hello',\n",
       " 'person',\n",
       " 'waiting',\n",
       " 'may',\n",
       " 'try',\n",
       " 'month',\n",
       " 'hour',\n",
       " 'fine',\n",
       " 'girl',\n",
       " 'haha',\n",
       " 'people',\n",
       " 'heart',\n",
       " 'coming',\n",
       " 'minute',\n",
       " 'best',\n",
       " 'th',\n",
       " 'getting',\n",
       " 'yet',\n",
       " 'smile',\n",
       " 'done',\n",
       " 'thk',\n",
       " 'guaranteed',\n",
       " 'ppm',\n",
       " 'god',\n",
       " 'thought',\n",
       " 'use',\n",
       " 'offer',\n",
       " 'holiday',\n",
       " 'start',\n",
       " 'class',\n",
       " 'stuff',\n",
       " 'talk',\n",
       " 'man',\n",
       " 'car',\n",
       " 'lunch',\n",
       " 'cost',\n",
       " 'line',\n",
       " 'live',\n",
       " 'mean',\n",
       " 'bit',\n",
       " 'job',\n",
       " 'finish',\n",
       " 'draw',\n",
       " 'problem',\n",
       " 'never',\n",
       " 'plan',\n",
       " 'better',\n",
       " 'meeting',\n",
       " 'hr',\n",
       " 'thats',\n",
       " 'trying',\n",
       " 'house',\n",
       " 'yup',\n",
       " 'ill',\n",
       " 'cool',\n",
       " 'rate',\n",
       " 'mind',\n",
       " 'long',\n",
       " 'dat',\n",
       " 'pobox',\n",
       " 'account',\n",
       " 'ready',\n",
       " 'weekend',\n",
       " 'chance',\n",
       " 'game',\n",
       " 'real',\n",
       " 'enjoy',\n",
       " 'half',\n",
       " 'world',\n",
       " 'wk',\n",
       " 'latest',\n",
       " 'bt',\n",
       " 'po',\n",
       " 'play',\n",
       " 'yo',\n",
       " 'guess',\n",
       " 'sir',\n",
       " 'check',\n",
       " 'room',\n",
       " 'wanna',\n",
       " 'sweet',\n",
       " 'eat',\n",
       " 'camera',\n",
       " 'voucher',\n",
       " 'nothing',\n",
       " 'pic',\n",
       " 'look',\n",
       " 'receive',\n",
       " 'luv',\n",
       " 'lar',\n",
       " 'boy',\n",
       " 'awarded',\n",
       " 'another',\n",
       " 'shit',\n",
       " 'big',\n",
       " 'liao',\n",
       " 'landline',\n",
       " 'dinner',\n",
       " 'birthday',\n",
       " 'ah',\n",
       " 'xxx',\n",
       " 'age',\n",
       " 'video',\n",
       " 'jus',\n",
       " 'quite',\n",
       " 'ever',\n",
       " 'kiss',\n",
       " 'might',\n",
       " 'watching',\n",
       " 'wont',\n",
       " 'land',\n",
       " 'question',\n",
       " 'watch',\n",
       " 'tv',\n",
       " 'early',\n",
       " 'fun',\n",
       " 'probably',\n",
       " 'orange',\n",
       " 'bed',\n",
       " 'dream',\n",
       " 'aight',\n",
       " 'hear',\n",
       " 'thanx',\n",
       " 'two',\n",
       " 'worry',\n",
       " 'baby',\n",
       " 'speak',\n",
       " 'pa',\n",
       " 'nd',\n",
       " 'point',\n",
       " 'called',\n",
       " 'nite',\n",
       " 'maybe',\n",
       " 'apply',\n",
       " 'left',\n",
       " 'bus',\n",
       " 'forgot',\n",
       " 'ringtone',\n",
       " 'actually',\n",
       " 'sat',\n",
       " 'network',\n",
       " 'princess',\n",
       " 'bad',\n",
       " 'remember',\n",
       " 'den',\n",
       " 'shall',\n",
       " 'pay',\n",
       " 'part',\n",
       " 'code',\n",
       " 'shopping',\n",
       " 'office',\n",
       " 'reach',\n",
       " 'made',\n",
       " 'dunno',\n",
       " 'hurt',\n",
       " 'easy',\n",
       " 'fuck',\n",
       " 'leh',\n",
       " 'dad',\n",
       " 'face',\n",
       " 'little',\n",
       " 'everything',\n",
       " 'anyway',\n",
       " 'wife',\n",
       " 'true',\n",
       " 'xx',\n",
       " 'put',\n",
       " 'didnt',\n",
       " 'evening',\n",
       " 'award',\n",
       " 'dis',\n",
       " 'afternoon',\n",
       " 'town',\n",
       " 'movie',\n",
       " 'school',\n",
       " 'gift',\n",
       " 'enough',\n",
       " 'mate',\n",
       " 'sound',\n",
       " 'thank',\n",
       " 'working',\n",
       " 'looking',\n",
       " 'selected',\n",
       " 'yr',\n",
       " 'mail',\n",
       " 'entry',\n",
       " 'missing',\n",
       " 'pound',\n",
       " 'collect',\n",
       " 'asked',\n",
       " 'detail',\n",
       " 'tmr',\n",
       " 'without',\n",
       " 'though',\n",
       " 'join',\n",
       " 'important',\n",
       " 'hav',\n",
       " 'wif',\n",
       " 'must',\n",
       " 'xmas',\n",
       " 'wanted',\n",
       " 'pain',\n",
       " 'sexy',\n",
       " 'came',\n",
       " 'valid',\n",
       " 'okay',\n",
       " 'since',\n",
       " 'price',\n",
       " 'answer',\n",
       " 'wot',\n",
       " 'abt',\n",
       " 'lesson',\n",
       " 'able',\n",
       " 'wake',\n",
       " 'collection',\n",
       " 'til',\n",
       " 'update',\n",
       " 'mob',\n",
       " 'run',\n",
       " 'book',\n",
       " 'missed',\n",
       " 'bring',\n",
       " 'plus',\n",
       " 'stay',\n",
       " 'plz',\n",
       " 'decimal',\n",
       " 'charge',\n",
       " 'date',\n",
       " 'away',\n",
       " 'de',\n",
       " 'juz',\n",
       " 'wen',\n",
       " 'test',\n",
       " 'change',\n",
       " 'colour',\n",
       " 'alright',\n",
       " 'hair',\n",
       " 'bored',\n",
       " 'double',\n",
       " 'attempt',\n",
       " 'music',\n",
       " 'yesterday',\n",
       " 'weekly',\n",
       " 'else',\n",
       " 'till',\n",
       " 'shop',\n",
       " 'dude',\n",
       " 'saw',\n",
       " 'havent',\n",
       " 'goin',\n",
       " 'online',\n",
       " 'drink',\n",
       " 'optout',\n",
       " 'friendship',\n",
       " 'oso',\n",
       " 'id',\n",
       " 'lei',\n",
       " 'top',\n",
       " 'net',\n",
       " 'haf',\n",
       " 'trip',\n",
       " 'credit',\n",
       " 'coz',\n",
       " 'making',\n",
       " 'food',\n",
       " 'player',\n",
       " 'either',\n",
       " 'sch',\n",
       " 'feeling',\n",
       " 'family',\n",
       " 'national',\n",
       " 'ard',\n",
       " 'hot',\n",
       " 'delivery',\n",
       " 'address',\n",
       " 'club',\n",
       " 'driving',\n",
       " 'gr',\n",
       " 'smoke',\n",
       " 'tried',\n",
       " 'http',\n",
       " 'lose',\n",
       " 'mom',\n",
       " 'full',\n",
       " 'wid',\n",
       " 'sae',\n",
       " 'bonus',\n",
       " 'head',\n",
       " 'post',\n",
       " 'second',\n",
       " 'walk',\n",
       " 'beautiful',\n",
       " 'ring',\n",
       " 'calling',\n",
       " 'busy',\n",
       " 'order',\n",
       " 'story',\n",
       " 'si',\n",
       " 'sad',\n",
       " 'believe',\n",
       " 'brother',\n",
       " 'together',\n",
       " 'tot',\n",
       " 'nt',\n",
       " 'mum',\n",
       " 'happen',\n",
       " 'close',\n",
       " 'smiling',\n",
       " 'await',\n",
       " 'hand',\n",
       " 'info',\n",
       " 'drive',\n",
       " 'old',\n",
       " 'leaving',\n",
       " 'sleeping',\n",
       " 'row',\n",
       " 'chikku',\n",
       " 'huh',\n",
       " 'set',\n",
       " 'saying',\n",
       " 'poly',\n",
       " 'eve',\n",
       " 'noe',\n",
       " 'email',\n",
       " 'private',\n",
       " 'started',\n",
       " 'finished',\n",
       " 'match',\n",
       " 'hl',\n",
       " 'drop',\n",
       " 'okie',\n",
       " 'cause',\n",
       " 'news',\n",
       " 'took',\n",
       " 'congrats',\n",
       " 'parent',\n",
       " 'mths',\n",
       " 'suite',\n",
       " 'aft',\n",
       " 'tomo',\n",
       " 'rite',\n",
       " 'pub',\n",
       " 'thinking',\n",
       " 'wil',\n",
       " 'awesome',\n",
       " 'simple',\n",
       " 'forget',\n",
       " 'unsubscribe',\n",
       " 'auction',\n",
       " 'reason',\n",
       " 'caller',\n",
       " 'content',\n",
       " 'available',\n",
       " 'neva',\n",
       " 'sister',\n",
       " 'mine',\n",
       " 'anyone',\n",
       " 'final',\n",
       " 'tho',\n",
       " 'gd',\n",
       " 'card',\n",
       " 'valentine',\n",
       " 'angry',\n",
       " 'tc',\n",
       " 'company',\n",
       " 'taking',\n",
       " 'break',\n",
       " 'statement',\n",
       " 'everyone',\n",
       " 'touch',\n",
       " 'expires',\n",
       " 'whats',\n",
       " 'open',\n",
       " 'type',\n",
       " 'search',\n",
       " 'treat',\n",
       " 'found',\n",
       " 'opt',\n",
       " 'dating',\n",
       " 'sun',\n",
       " 'whatever',\n",
       " 'knw',\n",
       " 'ticket',\n",
       " 'alone',\n",
       " 'fancy',\n",
       " 'choose',\n",
       " 'lucky',\n",
       " 'bank',\n",
       " 'carlos',\n",
       " 'gal',\n",
       " 'worth',\n",
       " 'loving',\n",
       " 'hows',\n",
       " 'bout',\n",
       " 'welcome',\n",
       " 'smth',\n",
       " 'ha',\n",
       " 'saturday',\n",
       " 'exam',\n",
       " 'uncle',\n",
       " 'happened',\n",
       " 'party',\n",
       " 'identifier',\n",
       " 'quiz',\n",
       " 'kind',\n",
       " 'nyt',\n",
       " 'hard',\n",
       " 'visit',\n",
       " 'college',\n",
       " 'wonderful',\n",
       " 'sub',\n",
       " 'frnd',\n",
       " 'fast',\n",
       " 'winner',\n",
       " 'mobileupd',\n",
       " 'ni',\n",
       " 'boytoy',\n",
       " 'ltd',\n",
       " 'decided',\n",
       " 'friday',\n",
       " 'gbp',\n",
       " 'anytime',\n",
       " 'prob',\n",
       " 'song',\n",
       " 'hit',\n",
       " 'gone',\n",
       " 'far',\n",
       " 'congratulation',\n",
       " 'secret',\n",
       " 'used',\n",
       " 'project',\n",
       " 'tel',\n",
       " 'oredi',\n",
       " 'finally',\n",
       " 'goodmorning',\n",
       " 'mu',\n",
       " 'pretty',\n",
       " 'sea',\n",
       " 'light',\n",
       " 'read',\n",
       " 'term',\n",
       " 'nope',\n",
       " 'darlin',\n",
       " 'mrng',\n",
       " 'outside',\n",
       " 'fri',\n",
       " 'camcorder',\n",
       " 'fucking',\n",
       " 'operator',\n",
       " 'crazy',\n",
       " 'wit',\n",
       " 'drug',\n",
       " 'chennai',\n",
       " 'hold',\n",
       " 'wonder',\n",
       " 'lovely',\n",
       " 'least',\n",
       " 'wrong',\n",
       " 'support',\n",
       " 'blue',\n",
       " 'savamob',\n",
       " 'earlier',\n",
       " 'snow',\n",
       " 'wkly',\n",
       " 'fone',\n",
       " 'frm',\n",
       " 'freemsg',\n",
       " 'course',\n",
       " 'whole',\n",
       " 'frnds',\n",
       " 'log',\n",
       " 'cd',\n",
       " 'le',\n",
       " 'listen',\n",
       " 'meant',\n",
       " 'sunday',\n",
       " 'hmm',\n",
       " 'hungry',\n",
       " 'jay',\n",
       " 'case',\n",
       " 'ten',\n",
       " 'unlimited',\n",
       " 'fr',\n",
       " 'wq',\n",
       " 'telling',\n",
       " 'seeing',\n",
       " 'cum',\n",
       " 'john',\n",
       " 'rock',\n",
       " 'currently',\n",
       " 'mr',\n",
       " 'father',\n",
       " 'india',\n",
       " 'understand',\n",
       " 'hmmm',\n",
       " 'as',\n",
       " 'dnt',\n",
       " 'gas',\n",
       " 'knew',\n",
       " 'hee',\n",
       " 'motorola',\n",
       " 'enter',\n",
       " 'invited',\n",
       " 'side',\n",
       " 'felt',\n",
       " 'child',\n",
       " 'store',\n",
       " 'download',\n",
       " 'gn',\n",
       " 'moment',\n",
       " 'na',\n",
       " 'film',\n",
       " 'luck',\n",
       " 'couple',\n",
       " 'mah',\n",
       " 'single',\n",
       " 'christmas',\n",
       " 'sex',\n",
       " 'stupid',\n",
       " 'etc',\n",
       " 'reading',\n",
       " 'within',\n",
       " 'un',\n",
       " 'balance',\n",
       " 'almost',\n",
       " 'tired',\n",
       " 'valued',\n",
       " 'lost',\n",
       " 'eh',\n",
       " 'yar',\n",
       " 'computer',\n",
       " 'pas',\n",
       " 'press',\n",
       " 'happiness',\n",
       " 'joy',\n",
       " 'txts',\n",
       " 'move',\n",
       " 'area',\n",
       " 'cut',\n",
       " 'bslvyl',\n",
       " 'march',\n",
       " 'paper',\n",
       " 'die',\n",
       " 'sk',\n",
       " 'load',\n",
       " 'park',\n",
       " 'ago',\n",
       " 'mayb',\n",
       " 'talking',\n",
       " 'sell',\n",
       " 'gym',\n",
       " 'wow',\n",
       " 'ac',\n",
       " 'difficult',\n",
       " 'surprise',\n",
       " 'askd',\n",
       " 'ugh',\n",
       " 'complimentary',\n",
       " 'shower',\n",
       " 'gotta',\n",
       " 'photo',\n",
       " 'ipod',\n",
       " 'direct',\n",
       " 'comp',\n",
       " 'red',\n",
       " 'return',\n",
       " 'via',\n",
       " 'darren',\n",
       " 'laptop',\n",
       " 'reveal',\n",
       " 'max',\n",
       " 'an',\n",
       " 'figure',\n",
       " 'bcoz',\n",
       " 'ish',\n",
       " 'extra',\n",
       " 'hospital',\n",
       " 'promise',\n",
       " 'sending',\n",
       " 'heard',\n",
       " 'grin',\n",
       " 'bill',\n",
       " 'information',\n",
       " 'swing',\n",
       " 'xy',\n",
       " 'confirm',\n",
       " 'rental',\n",
       " 'picking',\n",
       " 'kid',\n",
       " 'charged',\n",
       " 'doin',\n",
       " 'ge',\n",
       " 'supposed',\n",
       " 'redeemed',\n",
       " 'seen',\n",
       " 'semester',\n",
       " 'correct',\n",
       " 'eye',\n",
       " 'met',\n",
       " 'lady',\n",
       " 'sort',\n",
       " 'fact',\n",
       " 'discount',\n",
       " 'hg',\n",
       " 'eg',\n",
       " 'comin',\n",
       " 'study',\n",
       " 'checking',\n",
       " 'fantasy',\n",
       " 'ex',\n",
       " 'std',\n",
       " 'request',\n",
       " 'road',\n",
       " 'clean',\n",
       " 'hmv',\n",
       " 'asap',\n",
       " 'leaf',\n",
       " 'train',\n",
       " 'txting',\n",
       " 'wana',\n",
       " 'whenever',\n",
       " 'noon',\n",
       " 'reward',\n",
       " 'somebody',\n",
       " 'lover',\n",
       " 'door',\n",
       " 'police',\n",
       " 'slowly',\n",
       " 'rest',\n",
       " 'loved',\n",
       " 'wap',\n",
       " 'link',\n",
       " 'pete',\n",
       " 'laugh',\n",
       " 'lovable',\n",
       " 'joke',\n",
       " 'blood',\n",
       " 'small',\n",
       " 'truth',\n",
       " 'weed',\n",
       " 'slow',\n",
       " 'usf',\n",
       " 'entered',\n",
       " 'kate',\n",
       " 'yep',\n",
       " 'rent',\n",
       " 'crave',\n",
       " 'idea',\n",
       " 'loan',\n",
       " 'safe',\n",
       " 'rply',\n",
       " 'abiola',\n",
       " 'nobody',\n",
       " 'monday',\n",
       " 'page',\n",
       " 'remove',\n",
       " 'bath',\n",
       " 'cheer',\n",
       " 'muz',\n",
       " 'save',\n",
       " 'asking',\n",
       " 'orchard',\n",
       " 'dogging',\n",
       " 'member',\n",
       " 'wine',\n",
       " 'write',\n",
       " 'sale',\n",
       " 'med',\n",
       " 'copy',\n",
       " 'la',\n",
       " 'spend',\n",
       " 'callertune',\n",
       " 'normal',\n",
       " 'convey',\n",
       " 'reached',\n",
       " 'worried',\n",
       " 'merry',\n",
       " 'ldn',\n",
       " 'voice',\n",
       " 'mistake',\n",
       " 'bb',\n",
       " 'cover',\n",
       " 'cheap',\n",
       " 'ringtones',\n",
       " 'immediately',\n",
       " 'hoping',\n",
       " 'warm',\n",
       " 'getzed',\n",
       " 'deep',\n",
       " 'il',\n",
       " 'poor',\n",
       " 'gap',\n",
       " 'gave',\n",
       " 'em',\n",
       " 'different',\n",
       " 'usual',\n",
       " 'men',\n",
       " 'otherwise',\n",
       " 'ntt',\n",
       " 'cr',\n",
       " 'doctor',\n",
       " 'indian',\n",
       " 'oops',\n",
       " 'glad',\n",
       " 'ho',\n",
       " 'tonite',\n",
       " 'energy',\n",
       " 'pray',\n",
       " 'sony',\n",
       " 'somewhere',\n",
       " 'del',\n",
       " 'booked',\n",
       " 'wc',\n",
       " 'mm',\n",
       " 'fantastic',\n",
       " 'custcare',\n",
       " 'summer',\n",
       " 'opinion',\n",
       " 'forever',\n",
       " 'teach',\n",
       " 'rakhesh',\n",
       " 'deal',\n",
       " 'representative',\n",
       " 'hw',\n",
       " 'street',\n",
       " 'across',\n",
       " 'catch',\n",
       " 'king',\n",
       " 'bag',\n",
       " 'empty',\n",
       " 'woke',\n",
       " 'near',\n",
       " 'england',\n",
       " 'situation',\n",
       " 'admirer',\n",
       " 'short',\n",
       " 'cup',\n",
       " 'kick',\n",
       " 'turn',\n",
       " 'water',\n",
       " 'bathe',\n",
       " 'gettin',\n",
       " 'rd',\n",
       " 'wishing',\n",
       " 'nah',\n",
       " 'bluetooth',\n",
       " 'self',\n",
       " 'flag',\n",
       " 'ice',\n",
       " 'sunshine',\n",
       " 'style',\n",
       " 'rose',\n",
       " 'unless',\n",
       " 'result',\n",
       " 'reference',\n",
       " 'excellent',\n",
       " 'kinda',\n",
       " 'specially',\n",
       " 'tear',\n",
       " 'reaching',\n",
       " 'digital',\n",
       " 'sick',\n",
       " 'none',\n",
       " 'decide',\n",
       " 'seriously',\n",
       " 'sport',\n",
       " 'moral',\n",
       " 'flight',\n",
       " 'rcvd',\n",
       " 'bos',\n",
       " 'access',\n",
       " 'mon',\n",
       " 'mo',\n",
       " 'round',\n",
       " 'urself',\n",
       " 'al',\n",
       " 'logo',\n",
       " 'cake',\n",
       " 'iam',\n",
       " 'gay',\n",
       " 'ending',\n",
       " 'meh',\n",
       " 'hotel',\n",
       " 'brings',\n",
       " 'sofa',\n",
       " 'buying',\n",
       " 'accept',\n",
       " 'coffee',\n",
       " 'hiya',\n",
       " 'password',\n",
       " 'silent',\n",
       " 'mode',\n",
       " 'tht',\n",
       " 'wondering',\n",
       " 'others',\n",
       " 'rain',\n",
       " 'add',\n",
       " 'user',\n",
       " 'especially',\n",
       " 'disturb',\n",
       " 'trust',\n",
       " 'thinkin',\n",
       " 'possible',\n",
       " 'fall',\n",
       " 'bx',\n",
       " 'using',\n",
       " 'bold',\n",
       " 'ip',\n",
       " 'dead',\n",
       " 'ive',\n",
       " 'colleague',\n",
       " 'excuse',\n",
       " 'lazy',\n",
       " 'norm',\n",
       " 'ldew',\n",
       " 'bid',\n",
       " 'starting',\n",
       " 'lect',\n",
       " 'comuk',\n",
       " 'goodnight',\n",
       " 'charity',\n",
       " 'pc',\n",
       " 'studying',\n",
       " 'mrt',\n",
       " 'forwarded',\n",
       " 'seems',\n",
       " 'tampa',\n",
       " 'stand',\n",
       " 'completely',\n",
       " 'sitting',\n",
       " 'staying',\n",
       " 'doesnt',\n",
       " 'slave',\n",
       " 'finger',\n",
       " 'fat',\n",
       " 'tuesday',\n",
       " 'apartment',\n",
       " 'cute',\n",
       " 'file',\n",
       " 'wednesday',\n",
       " 'fill',\n",
       " 'list',\n",
       " 'issue',\n",
       " 'slept',\n",
       " 'miracle',\n",
       " 'omg',\n",
       " 'er',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jx0BwbNskrG5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def avg_w2v(doc):\n",
    "  return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2db1qtT4krOS",
    "outputId": "33be0370-78c9-4105-e045-13df000b245b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQLXjQ_gmlEL",
    "outputId": "c62a48f0-dc7a-4e54-b0b4-c73622efa9c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5564 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 5564/5564 [00:00<00:00, 6174.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X = []\n",
    "for i in tqdm(range(len(words))):\n",
    "  X.append(avg_w2v(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dD7XfzZMnX9W",
    "outputId": "558fedee-569c-41c5-8ea4-1e4c63576fd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-e4745e086aca>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_new = np.array(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([-9.94118825e-02,  2.62355953e-01,  1.30776167e-01,  4.09326665e-02,\n",
       "               4.67418395e-02, -3.18318814e-01,  6.66933432e-02,  5.50204694e-01,\n",
       "              -1.51552379e-01, -1.43699721e-01, -1.55192748e-01, -3.73110652e-01,\n",
       "              -4.50148098e-02,  1.28540054e-01,  7.56562054e-02, -2.77048975e-01,\n",
       "               9.29836929e-03, -3.57254356e-01, -1.99265163e-02, -4.37370151e-01,\n",
       "               9.49602947e-02,  1.60774231e-01,  1.07813783e-01, -1.00628465e-01,\n",
       "              -9.81419012e-02,  7.05115322e-04, -2.04392031e-01, -1.62030414e-01,\n",
       "              -2.59680510e-01,  4.17851768e-02,  2.72571743e-01,  7.07961693e-02,\n",
       "               1.46322295e-01, -2.80888349e-01, -1.20870329e-01,  2.60931104e-01,\n",
       "               3.03471405e-02, -2.16828883e-01, -1.50460184e-01, -3.97943139e-01,\n",
       "               5.82178347e-02, -2.45827481e-01, -9.65053439e-02,  8.92117396e-02,\n",
       "               2.58165061e-01, -1.45799771e-01, -1.89455450e-01,  3.40956561e-02,\n",
       "               1.53390348e-01,  2.16191009e-01,  1.72013417e-01, -2.86992401e-01,\n",
       "              -2.50314008e-02, -3.88993323e-02, -1.43334851e-01,  2.08279192e-01,\n",
       "               1.63404658e-01, -6.27110600e-02, -2.91005254e-01,  5.67805655e-02,\n",
       "               8.77988338e-02,  1.40029192e-01, -1.26519278e-01, -2.39104033e-04,\n",
       "              -2.69907087e-01,  1.75046444e-01,  9.34165716e-02,  2.25761309e-01,\n",
       "              -2.63208717e-01,  3.19059223e-01, -1.85245439e-01,  1.48944318e-01,\n",
       "               2.96927661e-01, -6.99496493e-02,  2.98491120e-01,  1.91330329e-01,\n",
       "               3.75623093e-03, -1.12772085e-01, -1.92998484e-01,  1.06092818e-01,\n",
       "              -1.24905020e-01,  4.72114747e-03, -2.25687429e-01,  3.37767452e-01,\n",
       "              -4.81576771e-02,  5.96346520e-03, -1.09725535e-01,  3.42593402e-01,\n",
       "               3.65160853e-01,  9.41290259e-02,  3.73587757e-01,  1.55051947e-01,\n",
       "               8.76480713e-02,  1.37223974e-01,  3.48817229e-01,  3.10495615e-01,\n",
       "               1.24083675e-01, -3.02032202e-01,  9.50208232e-02, -7.35567659e-02],\n",
       "             dtype=float32)                                                       ,\n",
       "       array([-0.06264496,  0.17671095,  0.08335306,  0.0259166 ,  0.03045699,\n",
       "              -0.2087374 ,  0.04540063,  0.362117  , -0.10207608, -0.09513223,\n",
       "              -0.10542999, -0.24748807, -0.0268399 ,  0.0882813 ,  0.04471973,\n",
       "              -0.18223558,  0.00959336, -0.23411098, -0.01762629, -0.2926526 ,\n",
       "               0.06239324,  0.10349709,  0.06857067, -0.07039282, -0.06341854,\n",
       "               0.00271415, -0.13369152, -0.10298537, -0.16974646,  0.03117521,\n",
       "               0.18096174,  0.04354402,  0.09736393, -0.18769237, -0.07490528,\n",
       "               0.17588048,  0.02142261, -0.1436226 , -0.09693704, -0.2682879 ,\n",
       "               0.03762987, -0.16196153, -0.06243176,  0.05711184,  0.16979389,\n",
       "              -0.0955401 , -0.12389486,  0.01600016,  0.10299821,  0.14703272,\n",
       "               0.11123272, -0.19101493, -0.02183221, -0.02508474, -0.09879214,\n",
       "               0.13915674,  0.10171719, -0.04909318, -0.19484141,  0.03402422,\n",
       "               0.06102563,  0.09215748, -0.08071906, -0.00063723, -0.18124811,\n",
       "               0.11456917,  0.0650086 ,  0.14351681, -0.1759874 ,  0.21545696,\n",
       "              -0.11775973,  0.09946014,  0.19465509, -0.04140733,  0.19841151,\n",
       "               0.12880151,  0.00152006, -0.0779653 , -0.12601624,  0.07275141,\n",
       "              -0.07954009, -0.00163862, -0.15188676,  0.22661278, -0.0301638 ,\n",
       "               0.00752813, -0.07236047,  0.22456834,  0.24094994,  0.0588587 ,\n",
       "               0.24461591,  0.10622215,  0.06036945,  0.0877548 ,  0.23076546,\n",
       "               0.20582779,  0.08364778, -0.19913499,  0.06147551, -0.04307202],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([-9.56896693e-02,  2.43554443e-01,  1.23173818e-01,  4.66189496e-02,\n",
       "               4.91305515e-02, -2.89722860e-01,  6.04403801e-02,  5.09058654e-01,\n",
       "              -1.39205456e-01, -1.26949683e-01, -1.43114001e-01, -3.41819644e-01,\n",
       "              -3.94725129e-02,  1.22218430e-01,  7.05166534e-02, -2.58754820e-01,\n",
       "               1.12061333e-02, -3.29392731e-01, -2.08707638e-02, -4.03505415e-01,\n",
       "               8.96320790e-02,  1.43352076e-01,  9.58449766e-02, -9.70371738e-02,\n",
       "              -8.93773288e-02,  3.70601984e-03, -1.86883211e-01, -1.56604543e-01,\n",
       "              -2.40998939e-01,  3.55411544e-02,  2.57991731e-01,  5.93063831e-02,\n",
       "               1.45819530e-01, -2.56824225e-01, -1.09838225e-01,  2.39544153e-01,\n",
       "               3.13333385e-02, -2.07704946e-01, -1.36537746e-01, -3.75927508e-01,\n",
       "               4.64871824e-02, -2.29863733e-01, -8.46501142e-02,  8.05453584e-02,\n",
       "               2.39605516e-01, -1.35743827e-01, -1.76549464e-01,  3.64383124e-02,\n",
       "               1.40895680e-01,  2.06379130e-01,  1.55709028e-01, -2.54821628e-01,\n",
       "              -2.84484215e-02, -3.38876024e-02, -1.25812709e-01,  1.94087446e-01,\n",
       "               1.48806408e-01, -5.67435250e-02, -2.68927157e-01,  5.52593954e-02,\n",
       "               8.15436319e-02,  1.29990444e-01, -1.14522673e-01,  4.38720919e-03,\n",
       "              -2.47289747e-01,  1.59310013e-01,  8.63033757e-02,  2.10048839e-01,\n",
       "              -2.48458624e-01,  3.00246030e-01, -1.65303737e-01,  1.43205225e-01,\n",
       "               2.81727344e-01, -7.00678229e-02,  2.71731287e-01,  1.74444169e-01,\n",
       "               7.85342781e-05, -1.03490591e-01, -1.79139912e-01,  1.05595514e-01,\n",
       "              -1.14978969e-01,  2.98095960e-03, -2.06991985e-01,  3.11531007e-01,\n",
       "              -4.73508239e-02,  2.72935396e-03, -1.05701789e-01,  3.20451111e-01,\n",
       "               3.41628015e-01,  9.01481658e-02,  3.49334836e-01,  1.45582110e-01,\n",
       "               8.74867886e-02,  1.21931419e-01,  3.26622069e-01,  2.90369809e-01,\n",
       "               1.10059455e-01, -2.79805481e-01,  8.78461450e-02, -6.81284815e-02],\n",
       "             dtype=float32)                                                       ,\n",
       "       ...,\n",
       "       array([-1.21892020e-02,  5.00264354e-02,  1.35428626e-02,  1.38381198e-02,\n",
       "               4.30386793e-03, -5.45279235e-02,  1.05708484e-02,  8.55700970e-02,\n",
       "              -2.18166858e-02, -2.10662223e-02, -2.67806482e-02, -7.04608336e-02,\n",
       "              -1.40556525e-02,  2.34795585e-02,  1.35124046e-02, -4.81156595e-02,\n",
       "              -7.78480899e-05, -5.50366715e-02, -1.92333199e-03, -6.87869266e-02,\n",
       "               2.40432713e-02,  3.03005967e-02,  1.72885731e-02, -2.02343781e-02,\n",
       "              -2.00041682e-02,  8.46934132e-03, -3.62865962e-02, -3.20906304e-02,\n",
       "              -4.27407473e-02,  1.16670318e-02,  5.14552370e-02,  2.41082744e-03,\n",
       "               2.81005427e-02, -5.34106568e-02, -2.57248804e-02,  4.09007110e-02,\n",
       "               6.40398776e-03, -4.17996608e-02, -2.76722983e-02, -6.42050952e-02,\n",
       "               1.20034898e-02, -4.34640571e-02, -1.03344647e-02,  8.71181581e-03,\n",
       "               5.19214720e-02, -1.94952600e-02, -3.06352116e-02, -8.47292016e-04,\n",
       "               1.90138035e-02,  3.05732116e-02,  2.47635134e-02, -5.64538725e-02,\n",
       "              -1.53199316e-03, -4.93462849e-03, -3.19658667e-02,  3.32363211e-02,\n",
       "               3.15233096e-02, -1.73878502e-02, -4.07662280e-02,  7.76443817e-03,\n",
       "               1.31383408e-02,  2.31844410e-02, -2.90388986e-02, -3.31251393e-03,\n",
       "              -5.16933836e-02,  2.85690892e-02,  2.27211453e-02,  3.99710611e-02,\n",
       "              -4.58891988e-02,  5.77819385e-02, -3.03039774e-02,  2.55797878e-02,\n",
       "               4.87087816e-02, -1.25953248e-02,  5.52559197e-02,  3.38174626e-02,\n",
       "               1.77754532e-03, -1.46792615e-02, -3.43937203e-02,  1.94216650e-02,\n",
       "              -2.09626202e-02, -1.24762161e-03, -3.77103798e-02,  5.29089533e-02,\n",
       "              -1.22059258e-02, -8.49310588e-03, -2.18887925e-02,  5.04883863e-02,\n",
       "               6.44579530e-02,  2.05767546e-02,  6.03405237e-02,  2.10703909e-02,\n",
       "               1.69202629e-02,  2.13337746e-02,  4.94266115e-02,  4.51227501e-02,\n",
       "               1.44958701e-02, -4.74185459e-02,  2.19380520e-02, -1.65007710e-02],\n",
       "             dtype=float32)                                                       ,\n",
       "       array([-0.10799427,  0.2787655 ,  0.14415656,  0.05221411,  0.04985397,\n",
       "              -0.33304211,  0.07042954,  0.5810833 , -0.16083072, -0.15159431,\n",
       "              -0.16381706, -0.39280355, -0.04193379,  0.13921237,  0.08058327,\n",
       "              -0.29617155,  0.00641598, -0.37823355, -0.02483118, -0.4627891 ,\n",
       "               0.101083  ,  0.16559781,  0.116675  , -0.11109319, -0.1029722 ,\n",
       "               0.00116904, -0.2150576 , -0.17388278, -0.27402237,  0.03901226,\n",
       "               0.29588044,  0.07061467,  0.1600727 , -0.2945657 , -0.12451515,\n",
       "               0.27546453,  0.03600211, -0.22820778, -0.15889953, -0.43024462,\n",
       "               0.05517484, -0.25929374, -0.10059941,  0.09030583,  0.2726353 ,\n",
       "              -0.15754817, -0.2003827 ,  0.0394012 ,  0.16417108,  0.23202443,\n",
       "               0.18225121, -0.30120853, -0.03045225, -0.04170337, -0.15007734,\n",
       "               0.22233525,  0.17080218, -0.06433104, -0.31060162,  0.05966658,\n",
       "               0.08819772,  0.14797427, -0.13167429, -0.00109259, -0.28554916,\n",
       "               0.18107146,  0.10155895,  0.2429931 , -0.2825671 ,  0.34482363,\n",
       "              -0.19221167,  0.1611883 ,  0.31791952, -0.07698386,  0.3129284 ,\n",
       "               0.20489782,  0.00321157, -0.11852611, -0.203823  ,  0.11517774,\n",
       "              -0.13347769,  0.00466638, -0.23824562,  0.35870972, -0.05224563,\n",
       "               0.00874926, -0.11564454,  0.3603555 ,  0.38931406,  0.10129921,\n",
       "               0.3900997 ,  0.162235  ,  0.09523068,  0.14207362,  0.37090647,\n",
       "               0.32989225,  0.1268133 , -0.31891167,  0.0986759 , -0.07826981],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([-0.0726335 ,  0.1919639 ,  0.09782354,  0.03271085,  0.03102223,\n",
       "              -0.2260611 ,  0.04666993,  0.3998383 , -0.11226331, -0.10394749,\n",
       "              -0.11969545, -0.27070224, -0.03546682,  0.09801847,  0.04679532,\n",
       "              -0.2042043 ,  0.00628968, -0.26506338, -0.01082404, -0.31222904,\n",
       "               0.07325221,  0.12051666,  0.08593323, -0.07838564, -0.07374251,\n",
       "               0.00581935, -0.15381354, -0.11768252, -0.19299173,  0.03602928,\n",
       "               0.20138766,  0.05429566,  0.11277917, -0.207556  , -0.08495656,\n",
       "               0.18701951,  0.01824955, -0.16366781, -0.10592532, -0.29583526,\n",
       "               0.04162951, -0.17837775, -0.06867725,  0.06751976,  0.1852268 ,\n",
       "              -0.11420631, -0.13746452,  0.02612616,  0.11500963,  0.15613008,\n",
       "               0.1325205 , -0.21252978, -0.01956914, -0.03613038, -0.10097202,\n",
       "               0.15421061,  0.11848214, -0.04686876, -0.20910402,  0.03939897,\n",
       "               0.06556291,  0.10625285, -0.08852463,  0.00075482, -0.19607258,\n",
       "               0.12326024,  0.066522  ,  0.1680879 , -0.19669665,  0.23579665,\n",
       "              -0.13586693,  0.1093782 ,  0.22233795, -0.04901161,  0.22351633,\n",
       "               0.14148702,  0.00152347, -0.07849801, -0.14306925,  0.08214225,\n",
       "              -0.08825208,  0.00309338, -0.1623948 ,  0.2547232 , -0.03622135,\n",
       "               0.00356752, -0.07914954,  0.2538825 ,  0.2721381 ,  0.0745362 ,\n",
       "               0.27788612,  0.10696006,  0.06496182,  0.09756286,  0.2580483 ,\n",
       "               0.22527409,  0.0868411 , -0.22243421,  0.06743839, -0.05386207],\n",
       "             dtype=float32)                                                    ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array(X)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDnZ9gzynlVb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17NLbwCLkAIo",
    "outputId": "6cbaeeb7-b9e4-48c4-d860-8071f577cf2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('second', 0.9894825220108032),\n",
       " ('haha', 0.9893098473548889),\n",
       " ('dude', 0.9892151355743408),\n",
       " ('charge', 0.9891514182090759),\n",
       " ('drive', 0.9891491532325745),\n",
       " ('dear', 0.9890168309211731),\n",
       " ('give', 0.9889749884605408),\n",
       " ('use', 0.9889550805091858),\n",
       " ('soon', 0.9889154434204102),\n",
       " ('well', 0.9888969659805298)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('slept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbVstxfQmkD3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4Cit_l_bmqe"
   },
   "outputs": [],
   "source": [
    "#BOW\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=True, max_features=2500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2-_R4Cfcqky"
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(messages['lable'])\n",
    "y = y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bl_3SsfIdf8T",
    "outputId": "cd7a56e4-f38c-46e0-cceb-a5cc4a06a0f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyHfj4m1dyp5"
   },
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h83TmVXVelj1",
    "outputId": "65f5c22b-2f88-46ac-90b6-9b16a4f25bd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([0, 0, 0, ..., 1, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02rYbA0reuzj",
    "outputId": "b508ca4b-df93-4c93-9766-c2c4910989e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 2500)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqmFTMDle37b"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPIvVRq_fv18"
   },
   "outputs": [],
   "source": [
    "y_pred = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYSvhNJZf23x"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6O37zP9PgJlx",
    "outputId": "d43b68da-b243-468b-fd04-f6c7e5deed77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820627802690582\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCCHm5T1gRlL",
    "outputId": "dee68d03-1b14-46ef-a09b-db6082b2eb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       959\n",
      "           1       0.93      0.95      0.94       156\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.97      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nw1GphDHoeEC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGjX_tddgh3x"
   },
   "outputs": [],
   "source": [
    "#TfIdf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "ti = TfidfVectorizer(max_features=2550)\n",
    "X = ti.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ba_oTe0orip"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou0RLM4nhj8o",
    "outputId": "b7d9c702-af8e-4a39-c7e6-cd117f6d3bd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2550)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_bn_u8ji5J6"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTfpPATQi6I-"
   },
   "outputs": [],
   "source": [
    "y_pred = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbspui7ejIHm",
    "outputId": "14f30831-1828-426d-e548-590f23a8df2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979372197309417\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3v20B47NjWnV",
    "outputId": "f97baac7-88be-442a-e028-ba9c9da190ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       976\n",
      "           1       0.86      0.99      0.92       139\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.93      0.99      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHnyK6K_jq4b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "spam_model = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DvLEhJEl_pf"
   },
   "outputs": [],
   "source": [
    "y_pred = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEk-KU8FmEbx",
    "outputId": "b40c1d69-a311-4fb4-b7b0-3f1a24ae97ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979372197309417\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WR7LRiHmLYc",
    "outputId": "82d30a51-0f3c-498c-f2bf-18b1cb321d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       976\n",
      "           1       0.86      0.99      0.92       139\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.93      0.99      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eJVzAEUmYxv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
